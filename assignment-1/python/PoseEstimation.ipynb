{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: mediapipe in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: keras in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (3.4.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.31)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.4.31)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moham\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\moham\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Downloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "   ---------------------------------------- 0.0/241.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/241.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/241.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/241.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/241.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/241.6 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/241.6 kB 187.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/241.6 kB 187.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/241.6 kB 187.9 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 41.0/241.6 kB 131.3 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 41.0/241.6 kB 131.3 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 71.7/241.6 kB 187.3 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 71.7/241.6 kB 187.3 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 71.7/241.6 kB 187.3 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 102.4/241.6 kB 196.9 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 102.4/241.6 kB 196.9 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/241.6 kB 206.3 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/241.6 kB 206.3 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 143.4/241.6 kB 213.0 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 143.4/241.6 kB 213.0 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 143.4/241.6 kB 213.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 153.6/241.6 kB 191.1 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 174.1/241.6 kB 201.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 184.3/241.6 kB 195.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 204.8/241.6 kB 207.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 225.3/241.6 kB 218.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 241.6/241.6 kB 227.9 kB/s eta 0:00:00\n",
      "Installing collected packages: rich\n",
      "Successfully installed rich-13.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001EE3CC07B90>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /compute/redist/rich/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001EE3CC07F50>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /compute/redist/rich/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001EE3CCEC1A0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /compute/redist/rich/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001EE3CCEC230>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /compute/redist/rich/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001EE3CCEC5F0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /compute/redist/rich/\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.utils.vis_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.vis_utils'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import mediapipe as mp\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Reshape, LSTM, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "#%matplotlib inline \n",
    "import copy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot Keypoints using MediaPipe Holistic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawText(img,sText,x,y):\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    posf = (x,y)\n",
    "    fontScale              = 5\n",
    "    fontColor              = (255,255,255)\n",
    "    thickness              = 1\n",
    "    lineType               = 2\n",
    "    print(\"Masuk\")\n",
    "    cv2.putText(img,sText, \n",
    "        posf, \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        thickness,\n",
    "        lineType)\n",
    "    return copy.deepcopy(img)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Initialize New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFileName():\n",
    "        x = datetime.datetime.now()\n",
    "        s = x.strftime('%Y-%m-%d-%H%M%S%f')\n",
    "        return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Create a New Directory to store File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDir(path):\n",
    "    ls = [];\n",
    "    head_tail = os.path.split(path)\n",
    "    ls.append(path)\n",
    "    while len(head_tail[1])>0:\n",
    "        head_tail = os.path.split(path)\n",
    "        path = head_tail[0]\n",
    "        ls.append(path)\n",
    "        head_tail = os.path.split(path)   \n",
    "    for i in range(len(ls)-2,-1,-1):\n",
    "        sf =ls[i]\n",
    "        isExist = os.path.exists(sf)\n",
    "        if not isExist:\n",
    "            os.makedirs(sf)\n",
    "NamaDataSet = \"Kata\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Landmarks / Create Skeletal Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(bimage, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "   # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                            # mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                            # mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                            # ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Dataset from LIVE Camera Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset(NoKamera,NamaDataSet):\n",
    "    DirektoriData = \"A:\\\\buat anaconda\\\\dataimage\"+\"\\\\\"+NamaDataSet\n",
    "    #+\"\\\\\"+GetFileName()    \n",
    "    CreateDir(DirektoriData)        \n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    imsize=(640, 480)\n",
    "    TimeStart = time.time() \n",
    "    TimeNow = time.time() +10\n",
    "    FrameRate = 10\n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(NoKamera,cv2.CAP_DSHOW)\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "      \n",
    "      while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "          print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "          continue\n",
    "    \n",
    "\n",
    "        image.flags.writeable = False                  # Image is no longer writeable\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, imsize)\n",
    "        results = holistic.process(image)                 # Make prediction\n",
    "        \n",
    "        image_height, image_width, _ = image.shape\n",
    "        \n",
    "        coords = []\n",
    "        coordsy = []\n",
    "      \n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "            \n",
    "        for A in results.pose_landmarks.landmark:\n",
    "            \n",
    "            if (A.x>0.01)and(A.x<1-0.01)and(A.y>0.01)and(A.y<1-0.01):\n",
    "                cx, cy = A.x * image_width, A.y*image_height \n",
    "                coords.append(cx) \n",
    "                coordsy.append(cy)\n",
    "        if len(coords) ==0:\n",
    "            continue\n",
    "        elif len(coordsy) ==0:\n",
    "            continue\n",
    "\n",
    "        #if results.pose_landmarks:\n",
    "        #    pose_landmarks = results.pose_landmarks.landmark\n",
    "        #    for A in pose_landmarks:\n",
    "        #      cx, cy = A.x * image_width, A.y*image_height                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "        #      coords.append(cx) \n",
    "        #      coordsy.append(cy) \n",
    "\n",
    "        x_max = max(coords)\n",
    "        y_max = max(coordsy)\n",
    "        x_min = min(coords)\n",
    "        y_min = min(coordsy)\n",
    "            \n",
    "\n",
    "        cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (255, 255, 0), 2)\n",
    "\n",
    "        if (int (x_max) < 0):\n",
    "            x_max = 1\n",
    "        elif (int (x_min) < 0):\n",
    "            x_min = 1\n",
    "        elif (int (x_max) < 0):\n",
    "            y_max = 1\n",
    "        elif (int (x_min) < 0):\n",
    "            y_min = 1   \n",
    "            \n",
    "        image.flags.writeable = True                   # Image is now writeable \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "        bimage = np.zeros((image_height,image_width,3), np.uint8)\n",
    "        cv2.rectangle(bimage,(int(x_min), int(y_min)),(int(x_max), int(y_max)),(0,255,0),2) #(KALAU MAU PAKAI BOUNDING BOX)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "        mp_drawing.draw_landmarks(bimage, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "      \n",
    "        \n",
    " \n",
    "              \n",
    "\n",
    "        image = cv2.rectangle(image,(int(x_min), int(y_min)),(int(x_max), int(y_max)),(255,255,0),2)\n",
    "        \n",
    " \n",
    "        cropped_image = bimage[(int(y_min)):(int(y_max)), (int(x_min)):(int(x_max)),:]\n",
    "        dy =y_max -y_min\n",
    "        dx = x_max -x_min\n",
    "        print(dy,dx)\n",
    "        print(cropped_image.shape) \n",
    "        TimeNow = time.time() \n",
    "        if TimeNow-TimeStart>1/FrameRate:\n",
    "            print(cropped_image.shape)\n",
    "            TimeStart = TimeNow\n",
    "            sFile = DirektoriData+\"\\\\\"+GetFileName()\n",
    "            imsize2=(128,128)\n",
    "            cropped_image = cv2.resize(cropped_image, imsize2)\n",
    "            #cropped_image = cv2.resize(bimage, imsize2)\n",
    "            cv2.imwrite(sFile+'.jpg', cropped_image)\n",
    "            #cv2.imwrite(sFile+'.png', image)\n",
    "        \n",
    "        cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "              break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict Pose based on Video Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictPose(NoKamera,LabelKelas):\n",
    "    ModelCNN = load_model('weight3_test.h5') \n",
    "    \n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    imsize=(640, 480)\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(NoKamera,cv2.CAP_DSHOW)\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "      \n",
    "      while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "          print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "          continue\n",
    "    \n",
    "\n",
    "        image.flags.writeable = False                  # Image is no longer writeable\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, imsize)\n",
    "        results = holistic.process(image)                 # Make prediction\n",
    "        \n",
    "        height, width, _ = image.shape\n",
    "        coords = []\n",
    "        coordsy = []\n",
    "                                                                                                                                  \n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "                continue\n",
    "        for A in results.pose_landmarks.landmark:\n",
    "\n",
    "            if (A.x>0.01)and(A.x<1-0.01)and(A.y>0.01)and(A.y<1-0.01):\n",
    "                cx, cy = A.x * width, A.y*height \n",
    "                coords.append(cx) \n",
    "                coordsy.append(cy)\n",
    "        if len(coords) ==0:\n",
    "            continue\n",
    "        if len(coordsy) ==0:\n",
    "            continue\n",
    "\n",
    "            #if results.pose_landmarks:\n",
    "            #    pose_landmarks = results.pose_landmarks.landmark\n",
    "            #    for A in pose_landmarks:\n",
    "            #      cx, cy = A.x * image_width, A.y*image_height                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            #      coords.append(cx) \n",
    "            #      coordsy.append(cy) \n",
    "\n",
    "        x_max = max(coords)\n",
    "        y_max = max(coordsy)\n",
    "        x_min = min(coords)\n",
    "        y_min = min(coordsy)\n",
    "        cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (255, 255, 0), 2)\n",
    "        \n",
    "        if (int (x_max) < 0):\n",
    "            x_max = 1\n",
    "        elif (int (x_min) < 0):\n",
    "            x_min = 1\n",
    "        elif (int (y_max) < 0):\n",
    "            y_max = 1\n",
    "        elif (int (y_min) < 0):\n",
    "            y_min = 1   \n",
    "        \n",
    "        image.flags.writeable = True                   # Image is now writeable \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "        bimage = np.zeros((height,width,3), np.uint8)\n",
    "        #cv2.rectangle(bimage,(int(x_min), int(y_min)),(int(x_max), int(y_max)),(0,255,0),2)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "        mp_drawing.draw_landmarks(bimage, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "       \n",
    "        \n",
    "         \n",
    "              \n",
    "        cropped_image = image[(int(y_min)):(int(y_max)), (int(x_min)):(int(x_max)),:]\n",
    "        idx = Klasifikasi(bimage, ModelCNN)\n",
    "        x=60\n",
    "        y=60\n",
    "        image= cv2.flip(image, 1)\n",
    "    \n",
    "        if idx>=0:\n",
    "            cv2.putText(image,LabelKelas[idx], (x,y), cv2.FONT_HERSHEY_SIMPLEX,2.0, (255, 255, 0), 3)\n",
    "        \n",
    "\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "                \n",
    "       \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "              break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classification of Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Klasifikasi(Image,ModelCNN):\n",
    "\n",
    "  X=[]\n",
    "  ls = [];\n",
    "\n",
    "  img= copy.deepcopy(Image)\n",
    "  img=cv2.resize(img,(128,128))\n",
    "  img= np.asarray(img)/255\n",
    "  img=img.astype('float32')\n",
    "  X.append(img)  \n",
    "  X=np.array(X)\n",
    "  X=X.astype('float32')\n",
    "  hs=ModelCNN.predict(X,verbose=0)\n",
    "\n",
    "  if hs.max()>0.5:\n",
    "      idx = np.max(np.where( hs == hs.max()))\n",
    "  else:\n",
    "    idx=-1\n",
    "      \n",
    " \n",
    "  return idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Create a Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCNN(JumlahKelas):\n",
    "    input_img = Input(shape=(128, 128, 3)) \n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)  \n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)   \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)   \n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)   \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = Reshape((-1, 32))(x)\n",
    "    #x = LSTM(64, return_sequences=True, activation='relu')(x)\n",
    "    #x = LSTM(128, return_sequences=True, activation='relu')(x)\n",
    "    #x = LSTM(64, return_sequences=False, activation='relu')(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    #x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(50,activation='sigmoid')(x)\n",
    "    x = Dense(JumlahKelas,activation='softmax')(x)\n",
    "    ModelCNN = Model(input_img, x)  \n",
    "    ModelCNN.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    #ModelCNN.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    #sparse_categorical_crossentropy\n",
    "    #categorical_crossentropy\n",
    "    #plot_model(ModelCNN, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    return ModelCNN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Load Citra Training Data (Object Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCitraTraining(sDir,LabelKelas):\n",
    "  \n",
    "  JumlahKelas=len(LabelKelas)\n",
    "  TargetKelas = np.eye(JumlahKelas)\n",
    "  \n",
    "  # Menyiapkan variabel list untuk data menampung citra dan data target\n",
    "  X=[]#Menampung Data Citra\n",
    "  T=[]#Menampung Target\n",
    "  for i in range(len(LabelKelas)):    \n",
    "    #Membaca file citra di setiap direktori data set  \n",
    "    DirKelas = os.path.join(sDir, LabelKelas[i])\n",
    "    files = os.listdir(DirKelas)\n",
    "    \n",
    "    for f in files:\n",
    "      ff=f.lower()  \n",
    "      print(f)\n",
    "      #memilih citra dengan extensi jpg,jpeg,dan png\n",
    "      if (ff.endswith('.jpg')):\n",
    "         NmFile = os.path.join(DirKelas,f)\n",
    "         #membaca citra berwarna sebagai data bertipe double \n",
    "         img= np.double(cv2.imread(NmFile,1))\n",
    "         img=cv2.resize(img,(128,128));\n",
    "         #Normalisasi data citra menjadi sehingga maksimum menjadi 1\n",
    "         img= np.asarray(img)/255;\n",
    "         img=img.astype('float32')\n",
    "         #Menambahkan citra dan target ke daftar\n",
    "         X.append(img)\n",
    "         T.append(TargetKelas[i])\n",
    "     #--------akhir loop :Pfor f in files-----------------\n",
    "  #-----akhir  loop :for i in range(len(LabelKelas))----\n",
    "  \n",
    "  #Mengubah List Menjadi numppy array\n",
    "  X=np.array(X)\n",
    "  T=np.array(T)\n",
    "  X=X.astype('float32')\n",
    "  T=T.astype('float32')\n",
    "  return X,T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1. Train the CNN to Recognize => Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainCNNLSTM(DirektoriDataSet,LabelKelas,NamaFileBobot ='weight3_test.h5' ):\n",
    "    #tf.config.experimental_run_functions_eagerly(True)\n",
    "    #tf.data.experimental.enable_debug_mode()\n",
    "    #Membaca Data training dan label Kelas \n",
    "    X,D=LoadCitraTraining(DirektoriDataSet,LabelKelas)\n",
    "    JumlahKelas = len(LabelKelas)\n",
    "    #Membuat Model CNN\n",
    "    ModelCNNlstm =ModelCNN(JumlahKelas)\n",
    "    #Trainng\n",
    "    history = ModelCNNlstm.fit(X, D,epochs=20,validation_split=0.1)\n",
    "    #validation_split = 0.5\n",
    "    #Menyimpan hasil learning\n",
    "    ModelCNNlstm.save(NamaFileBobot)\n",
    "    #Mengembalikan output \n",
    "    return ModelCNNlstm,history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2. Make Predictions for the Pose based on Primary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TesPosePrediction(DirDataSet,DirKlasifikasi,LabelKelas,ModelCNN=[]):\n",
    "#Apabila parameter input ModelCNN tidak di isi maka\n",
    "#   akan menggunakan bobot pada file 'weight.h5\n",
    "  if not(ModelCNN):\n",
    "      ModelCNN = load_model('weight3_test.h5') \n",
    "      \n",
    "#Menyiapkan Data input Yang akan di kasifikasikan\n",
    "  X=[]\n",
    "  ls = [];\n",
    "  DirKelas = DirDataSet+\"\\\\\"+DirKlasifikasi\n",
    "  print(DirKelas)\n",
    "  files = os.listdir(DirKelas)\n",
    "  n=0;\n",
    "  for f in files:\n",
    "      ff=f.lower()  \n",
    "      print(f)\n",
    "      if (ff.endswith('.jpg')):\n",
    "         ls.append(ff) \n",
    "         NmFile = os.path.join(DirKelas,f)\n",
    "         img= cv2.imread(NmFile,1)\n",
    "         img=cv2.resize(img,(128,128))\n",
    "         img= np.asarray(img)/255\n",
    "         img=img.astype('float32')\n",
    "         X.append(img)\n",
    "     #----Akhir if-------------\n",
    "  #---Akhir For \n",
    "  X=np.array(X)\n",
    "  X=X.astype('float32')\n",
    "  #Melakukan prediksi Klasifikasi\n",
    "  hs=ModelCNN.predict(X)\n",
    "  \n",
    "  LKlasifikasi=[];\n",
    "  LKelasCitra =[];\n",
    "  n = X.shape[0]\n",
    "  for i in range(n):\n",
    "      v=hs[i,:]\n",
    "      if v.max()>0.5:\n",
    "          idx = np.max(np.where( v == v.max()))\n",
    "          LKelasCitra.append(LabelKelas[idx])\n",
    "      else:\n",
    "          idx=-1\n",
    "          LKelasCitra.append(\"-\")\n",
    "      #------akhir if\n",
    "      LKlasifikasi.append(idx);\n",
    "  #----akhir for\n",
    "  LKlasifikasi = np.array(LKlasifikasi)\n",
    "  return ls, hs, LKelasCitra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3. Collect Dataset and Store to Assigned Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil data set dan menyimpan ke folder\n",
    "Dataset(0,\"Paman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data Set\n",
    "DirektoriDataSet=\"D:\\\\temp\\\\trainingdataset4\"\n",
    "#   Data Set disimpan dalam direktori yang sama dengan nama kelas    \n",
    "\n",
    "#b. Label Data Set \n",
    "LabelKelas=(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\")\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#c. Inisialisasi parameter Training\n",
    "#JumlahEpoh = 100;\n",
    "\n",
    "#d. training\n",
    "ModelCNN,history = TrainCNNLSTM(DirektoriDataSet,LabelKelas )\n",
    "ModelCNN.summary()\n",
    "\n",
    "#c. Menampilkan Grafik Loss dan accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4. Predict Pose Test based on Classified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelKelas=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\"]\n",
    "\n",
    "PredictPose(0,LabelKelas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelKelas=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\"]\n",
    "DirektoriDataSet=\"D:\\\\temp\\\\trainingdataset4\"\n",
    "\n",
    "DirKlasifikasi=\"C\"\n",
    "Res = TesPosePrediction(DirektoriDataSet,DirKlasifikasi,LabelKelas)\n",
    "print(Res[0])\n",
    "print(Res[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Create a Confusion Matrix to Assess Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the predicted labels and true labels for test data\n",
    "X_test, D_test = LoadCitraTraining(DirektoriDataSet, LabelKelas)\n",
    "\n",
    "# Predict labels for the test data\n",
    "predicted_labels = ModelCNN.predict(X_test)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "true_labels = np.argmax(D_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(LabelKelas))\n",
    "plt.xticks(tick_marks, LabelKelas, rotation=45)\n",
    "plt.yticks(tick_marks, LabelKelas)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Determine Result Accuracy & Precision, Correction, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the predicted labels and true labels for test data\n",
    "X_test, D_test = LoadCitraTraining(DirektoriDataSet, LabelKelas)\n",
    "\n",
    "# Load or initialize your trained model\n",
    "model = load_model('weight3_test.h5')  # Replace 'path_to_your_model.h5' with the actual path to your model\n",
    "\n",
    "# Predict labels for the test data\n",
    "predicted_labels = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "true_labels = np.argmax(D_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision for each class\n",
    "precisions = precision_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Calculate recall for each class\n",
    "recalls = recall_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Calculate F1-score for each class\n",
    "f1_scores = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Print the precision, recall, and F1-score table\n",
    "print(\"Class\\t\\tPrecision\\t1-Precision\\tRecall\\t\\t1-Recall\\tF1-score\")\n",
    "for i in range(len(LabelKelas)):\n",
    "    print(\"{}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(LabelKelas[i], precisions[i], 1-precisions[i],\n",
    "                                                                         recalls[i], 1-recalls[i], f1_scores[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
